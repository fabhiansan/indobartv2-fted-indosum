#!/bin/bash

# --- Configuration ---
# !!! IMPORTANT: Set these paths according to your server environment !!!

# Path to the cleaned input text file generated by run_preprocessing.sh
# Example: INPUT_FILE="./data/cleaned_oscar_id.txt"
INPUT_FILE="./data/cleaned_oscar_id.txt"

# Directory where the trained tokenizer files (vocab.json, merges.txt) will be saved
# Example: OUTPUT_DIR="./indobart-tokenizer"
OUTPUT_DIR="./indobart-tokenizer"

# Target vocabulary size for the tokenizer
# Example: VOCAB_SIZE=50265
VOCAB_SIZE=50265

# Minimum frequency for tokens
# Example: MIN_FREQ=2
MIN_FREQ=2

# --- Script Execution ---
echo "Starting Tokenizer training..."
echo "Using input file: ${INPUT_FILE}"
echo "Output directory: ${OUTPUT_DIR}"
echo "Vocab size: ${VOCAB_SIZE}"
echo "Min frequency: ${MIN_FREQ}"

# Ensure the output directory exists
mkdir -p "${OUTPUT_DIR}"

# Run the Python tokenizer training script
python train_tokenizer.py \
    --input_files "${INPUT_FILE}" \
    --output_dir "${OUTPUT_DIR}" \
    --vocab_size ${VOCAB_SIZE} \
    --min_frequency ${MIN_FREQ}

# Check exit status
if [ $? -eq 0 ]; then
    echo "Tokenizer training script finished successfully."
else
    echo "Tokenizer training script failed. Check logs for details."
    exit 1
fi

echo "Tokenizer training complete. Files saved to ${OUTPUT_DIR}"
